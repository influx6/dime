// Autogenerated using the moz templater annotation.
//
//
package services

import (
	"context"
	"sync/atomic"
	"time"
)

//go:generate moz generate-file -fromFile ./complex128_service.go -toDir ./impl/complex128

// Complex128FromByteAdapter defines a function that that will take a channel of bytes and return a channel of complex128.
type Complex128FromByteAdapterWithContext func(context.Context, chan []byte) chan complex128

// Complex128ToByteAdapter defines a function that that will take a channel of bytes and return a channel of complex128.
type Complex128ToByteAdapter func(context.Context, chan complex128) chan []byte

// Complex128PartialCollect defines a function which returns a channel where the items of the incoming channel
// are buffered until the channel is closed or the context expires returning whatever was collected, and closing the returning channel.
// This function does not guarantee complete data.
func Complex128PartialCollect(ctx context.Context, waitTime time.Duration, in chan complex128) chan []complex128 {
	res := make(chan []complex128, 0)

	go func() {
		var buffer []complex128

		t := time.NewTimer(waitTime)
		defer t.Stop()

		for {
			select {
			case <-ctx.Done():
				res <- buffer
				close(res)
				return
			case data, ok := <-in:
				if !ok {
					res <- buffer
					close(res)
					return
				}

				buffer = append(buffer, data)
				continue
			case <-t.C:
				t.Reset(waitTime)
				continue
			}
		}
	}()

	return res
}

// Complex128Collect defines a function which returns a channel where the items of the incoming channel
// are buffered until the channel is closed, nothing will be returned if the channel given is not closed  or the context expires.
// Once done, returning channel is closed.
// This function guarantees complete data.
func Complex128Collect(ctx context.Context, waitTime time.Duration, in chan complex128) chan []complex128 {
	res := make(chan []complex128, 0)

	go func() {
		var buffer []complex128

		t := time.NewTimer(waitTime)
		defer t.Stop()

		for {
			select {
			case <-ctx.Done():
				close(res)
				return
			case data, ok := <-in:
				if !ok {
					res <- buffer
					close(res)
					return
				}

				buffer = append(buffer, data)
				continue
			case <-t.C:
				t.Reset(waitTime)
				continue
			}
		}
	}()

	return res
}

// Complex128Mutate defines a function which returns a channel where the items of the incoming channel
// are mutated based on a function, till the provided channel is closed.
// If the given channel is closed or if the context expires, the returning channel is closed as well.
// This function guarantees complete data.
func Complex128Mutate(ctx context.Context, waitTime time.Duration, mutateFn func(complex128) complex128, in chan complex128) chan complex128 {
	res := make(chan complex128, 0)

	go func() {
		t := time.NewTimer(waitTime)
		defer t.Stop()

		for {
			select {
			case <-ctx.Done():
				close(res)
				return
			case data, ok := <-in:
				if !ok {
					close(res)
					return
				}

				res <- mutateFn(data)
			case <-t.C:
				t.Reset(waitTime)
				continue
			}
		}
	}()

	return res
}

// Complex128Filter defines a function which returns a channel where the items of the incoming channel
// are filtered based on a function, till the provided channel is closed.
// If the given channel is closed or if the context expires, the returning channel is closed as well.
// This function guarantees complete data.
func Complex128Filter(ctx context.Context, waitTime time.Duration, filterFn func(complex128) bool, in chan complex128) chan complex128 {
	res := make(chan complex128, 0)

	go func() {
		t := time.NewTimer(waitTime)
		defer t.Stop()

		for {
			select {
			case <-ctx.Done():
				close(res)
				return
			case data, ok := <-in:
				if !ok {
					close(res)
					return
				}

				if !filterFn(data) {
					continue
				}

				res <- data
			case <-t.C:
				t.Reset(waitTime)
				continue
			}
		}
	}()

	return res
}

// Complex128CollectUntil defines a function which returns a channel where the items of the incoming channel
// are buffered until the data matches a given requirement provided through a function. If the function returns true
// then currently buffered data is returned and a new buffer is created. This is useful for batch collection based on
// specific criteria. If the channel is closed before the criteria is met, what data is left is sent down the returned channel,
// closing that channel. If the context expires then data gathered is returned and returning channel is closed.
// This function guarantees some data to be delivered.
func Complex128CollectUntil(ctx context.Context, waitTime time.Duration, condition func([]complex128) bool, in chan complex128) chan []complex128 {
	res := make(chan []complex128, 0)

	go func() {
		var buffer []complex128

		t := time.NewTimer(waitTime)
		defer t.Stop()

		for {
			select {
			case <-ctx.Done():
				close(res)
				return
			case data, ok := <-in:
				if !ok {
					res <- buffer
					close(res)
					return
				}

				buffer = append(buffer, data)

				// If we do not match the given criteria, then continue buffering.
				if condition(buffer) {
					continue
				}

				// We do match criteria, send buffered data, and reset buffer
				res <- buffer
				buffer = nil
			case <-t.C:
				t.Reset(waitTime)
				continue
			}
		}
	}()

	return res
}

// Complex128MergeWithoutOrder merges the incoming data from the complex128 into a single stream of complex128,
// merge collects data from all provided channels in turns, each giving a specified time to deliver, else
// skipped until another turn. Once all data is collected from each sender, then the data set is merged into
// a single slice and delivered to the returned channel.
// MergeWithoutOrder makes the following guarantees:
// 1. Items will be received in order and return in order of channels provided.
// 2. Returned channel will never return incomplete data where a channels return value is missing from its index.
// 3. If any channel is closed then all operation is stopped and the returned channel is closed.
// 4. If the context expires before items are complete then returned channel is closed.
// 5. It will continously collect order data for all channels until any of the above conditions are broken.
// 6. All channel data are collected once for the receiving scope, i.e a channels data will not be received twice into the return slice
//    but all channels will have a single data slot for a partial data collection session.
// 7. Will continue to gather data from provided channels until all are closed or the context has expired.
// 8. If any of the senders is nil then the returned channel will be closed, has this leaves things in an unstable state.
func Complex128MergeWithoutOrder(ctx context.Context, maxWaitTime time.Duration, senders ...chan complex128) chan []complex128 {
	res := make(chan []complex128, 0)

	for _, elem := range senders {
		if elem == nil {
			close(res)
			return res
		}
	}

	go func() {
		var index int

		total := len(senders)
		filled := make(map[int]complex128, 0)

		for {
			// if the current index has being filled, shift forward and reattempt loop.
			if _, ok := filled[index]; ok {
				index++
				continue
			}

			if len(filled) == total {
				var content []complex128

				for _, item := range filled {
					content = append(content, item)
				}

				res <- content

				index = 0
				filled = make(map[int]complex128, 0)
			}

			timer := time.NewTimer(maxWaitTime)

			select {
			case <-ctx.Done():
				close(res)
				timer.Stop()
				return
			case <-timer.C:
				switch index >= total {
				case true:
					index = 0
				case false:
					index++
				}
			case data, ok := <-senders[index]:
				if !ok {
					close(res)
					timer.Stop()
					return
				}

				filled[index] = data
				index++
			}

			timer.Stop()
		}
	}()

	return res
}

// Complex128MergeInOrder merges the incoming data from the complex128 into a single stream of complex128,
// merge collects data from all provided channels in turns, each giving a specified time to deliver, else
// skipped until another turn. Once all data is collected from each sender, then the data set is merged into
// a single slice and delivered to the returned channel.
// MergeInOrder makes the following guarantees:
// 1. Items will be received in order and return in order of channels provided.
// 2. Returned channel will never return incomplete data where a channels return value is missing from its index.
// 3. If any channel is closed then all operation is stopped and the returned channel is closed.
// 4. If the context expires before items are complete then returned channel is closed.
// 5. It will continously collect order data for all channels until any of the above conditions are broken.
// 6. All channel data are collected once for the receiving scope, i.e a channels data will not be received twice into the return slice
//    but all channels will have a single data slot for a partial data collection session.
// 7. Will continue to gather data from provided channels until all are closed or the context has expired.
// 8. If any of the senders is nil then the returned channel will be closed, has this leaves things in an unstable state.
func Complex128MergeInOrder(ctx context.Context, maxWaitTime time.Duration, senders ...chan complex128) chan []complex128 {
	res := make(chan []complex128, 0)

	for _, elem := range senders {
		if elem == nil {
			close(res)
			return res
		}
	}

	go func() {
		var index int

		total := len(senders)
		filled := make(map[int]complex128, 0)

		for {
			// if the current index has being filled, shift forward and reattempt loop.
			if _, ok := filled[index]; ok {
				index++
				continue
			}

			if len(filled) == total {
				var content []complex128

				for index := range senders {
					item := filled[index]
					content = append(content, item)
				}

				res <- content

				index = 0
				filled = make(map[int]complex128, 0)
			}

			timer := time.NewTimer(maxWaitTime)

			select {
			case <-ctx.Done():
				close(res)
				timer.Stop()
				return
			case <-timer.C:
				switch index >= total {
				case true:
					index = 0
				case false:
					index++
				}
			case data, ok := <-senders[index]:
				if !ok {
					close(res)
					timer.Stop()
					return
				}

				filled[index] = data
				index++
			}

			timer.Stop()
		}
	}()

	return res
}

// Complex128CombineParitallyWithoutOrder receives a giving stream of content from multiple channels, returning a single channel of a
// 2d slice, it sequentially tries to recieve data from each sender within a provided time duration, else skipping until it's next turn.
// This ensures every sender has adquate time to receive and reducing long blocked waits for a specific sender, more so, this reduces the
// overhead of managing multiple go-routined receving channels which are prone to goroutine ophaning or memory leaks.
// Complex128CombineParitallyWithoutOrder makes the following guarantees:
// 1. Items will be received in any order received from the channels provided.
// 2. Returned channel will never return incomplete data where a channels return value is missing from its index.
// 3. If any channel is closed then all operation is stopped and the returned channel is closed.
// 4. If the context expires before items are complete then returned channel is closed.
// 5. It will continously collect data in any order for all channels until any of the above conditions are broken.
// 6. All channel data are collected once for the receiving scope, i.e a channels data will not be received twice into the return slice
//    but all channels will have a single data slot for a partial data collection session.
// 7. Will continue to gather data from provided channels until all are closed or the context has expired.
// 8. If any of the senders is nil then the returned channel will be closed, has this leaves things in an unstable state.
func Complex128CombinePartiallyWithoutOrder(ctx context.Context, maxItemWait time.Duration, senders ...chan complex128) chan []complex128 {
	res := make(chan []complex128, 0)

	for _, elem := range senders {
		if elem == nil {
			close(res)
			return res
		}
	}

	go func() {
		content := make([]complex128, 0)

		var index int

		total := len(senders)
		filled := make(map[int]bool, 0)
		closed := make(map[int]bool, 0)

		var sendersClosed int

		for {
			// if the current index has being filled, shift forward and re-attempt loop.
			if filled[index] || closed[index] {
				index++
				continue
			}

			if len(content) == total {
				res <- content

				index = 0
				filled = make(map[int]bool, 0)
				content = make([]complex128, len(senders))
			}

			timer := time.NewTimer(maxItemWait)

			select {
			case <-ctx.Done():
				close(res)
				timer.Stop()
				return
			case <-timer.C:
				switch index >= total {
				case true:
					index = 0
				case false:
					index++
				}
			case data, ok := <-senders[index]:
				if !ok {
					timer.Stop()

					sendersClosed++
					closed[index] = true
					continue
				}

				content = append(content, data)
				filled[index] = true
				index++
			}

			timer.Stop()
		}

	}()

	return res
}

// Complex128CombineWithoutOrder receives a giving stream of content from multiple channels, returning a single channel of a
// 2d slice, it sequentially tries to recieve data from each sender within a provided time duration, else skipping until it's next turn.
// This ensures every sender has adquate time to receive and reducing long blocked waits for a specific sender, more so, this reduces the
// overhead of managing multiple go-routined receving channels which are prone to goroutine ophaning or memory leaks.
// Complex128CombineWithoutOrder makes the following guarantees:
// 1. Items will be received in any order received from the channels provided.
// 2. Returned channel will never return incomplete data where a channels return value is missing from its index.
// 3. If any channel is closed then all operation is stopped and the returned channel is closed.
// 4. If the context expires before items are complete then returned channel is closed.
// 5. It will continously collect data in any order for all channels until any of the above conditions are broken.
// 6. All channel data are collected once for the receiving scope, i.e a channels data will not be received twice into the return slice
//    but all channels will have a single data slot for a partial data collection session.
// 7. Will continue to gather data from provided channels until all are closed or the context has expired.
// 8. If any of the senders is nil then the returned channel will be closed, has this leaves things in an unstable state.
func Complex128CombineWithoutOrder(ctx context.Context, maxItemWait time.Duration, senders ...chan complex128) chan []complex128 {
	res := make(chan []complex128, 0)

	for _, elem := range senders {
		if elem == nil {
			close(res)
			return res
		}
	}

	go func() {
		content := make([]complex128, 0)

		var index int

		total := len(senders)
		filled := make(map[int]bool, 0)

		for {
			// if the current index has being filled, shift forward and reattempt loop.
			if filled[index] {
				index++
				continue
			}

			if len(content) == total {
				res <- content
				index = 0
				filled = make(map[int]bool, 0)
				content = make([]complex128, len(senders))
			}

			timer := time.NewTimer(maxItemWait)

			select {
			case <-ctx.Done():
				close(res)
				timer.Stop()
				return
			case <-timer.C:
				switch index >= total {
				case true:
					index = 0
				case false:
					index++
				}
			case data, ok := <-senders[index]:
				if !ok {
					close(res)
					timer.Stop()
					return
				}

				content = append(content, data)
				filled[index] = true
				index++
			}

			timer.Stop()
		}

	}()

	return res
}

// Complex128CombineInPartialOrder receives a giving stream of content from multiple channels, returning a single channel of a
// 2d slice, it sequentially tries to recieve data from each sender within a provided time duration, else skipping until it's next turn.
// This ensures every sender has adquate time to receive and reducing long blocked waits for a specific sender, more so, this reduces the
// overhead of managing multiple go-routined receving channels which are prone to goroutine ophaning or memory leaks.
// Complex128CombineInPartialOrder makes the following guarantees:
// 1. Items will be received in order and return in order of channels provided.
// 2. Returned channel will never return incomplete data where a channels return value is missing from its index.
// 3. If any channel is closed then all operation is not stopped and will continue but there will be an empty slot in the slice returned.
// 4. If the context expires before items are complete then returned channel is closed.
// 5. It will continously collect order data for all channels until any of the above conditions are broken.
// 6. All channel data are collected once for the receiving scope, i.e a channels data will not be received twice into the return slice
//    but all channels will have a single data slot for a partial data collection session.
// 7. Will continue to gather data from provided channels until all are closed or the context has expired.
// 8. If any of the senders is nil then the returned channel will be closed, has this leaves things in an unstable state.
func Complex128CombineInPartialOrder(ctx context.Context, maxItemWait time.Duration, senders ...chan complex128) chan []complex128 {
	res := make(chan []complex128, 0)

	for _, elem := range senders {
		if elem == nil {
			close(res)
			return res
		}
	}

	go func() {
		content := make([]complex128, len(senders))

		var index int

		total := len(senders)
		filled := make(map[int]bool, 0)
		closed := make(map[int]bool, 0)

		var sendersClosed int

		for {
			// if the current index has being filled, shift forward and reattempt loop.
			if filled[index] || closed[index] {
				index++
				continue
			}

			if sendersClosed >= total {
				res <- content
				return
			}

			if len(filled) == total {
				res <- content
				index = 0
				filled = make(map[int]bool, 0)
				content = make([]complex128, len(senders))
			}

			timer := time.NewTimer(maxItemWait)

			select {
			case <-ctx.Done():
				close(res)
				timer.Stop()
				return
			case <-timer.C:
				switch index >= total {
				case true:
					index = 0
				case false:
					index++
				}
			case data, ok := <-senders[index]:
				if !ok {
					timer.Stop()

					sendersClosed++
					closed[index] = true
					continue
				}

				content[index] = data
				filled[index] = true
				index++
			}

			timer.Stop()
		}

	}()

	return res
}

// Complex128CombineInOrder receives a giving stream of content from multiple channels, returning a single channel of a
// two slice type, more so, it will use the maxItemWait duration to give every channel a opportunity for delivery
// data. If the time is passed it will cycle to the next item, till the complete set is retrieved from, unless
// the context timout expires and causes a complete stop of operation. CombineInOrder guarantees that the data
// retrieved will be stored in order of passed in channels. If any of the channels is nil, then the returned
// channel will be closed.
// CombineInOrder makes the following guarantees:
// 1. Items will be received in order and return in order of channels provided.
// 2. Returned channel will never return incomplete data where a channels return value is missing from its index.
// 3. If any channel is closed then all operation is stopped and the returned channel is closed.
// 4. If the context expires before items are complete then returned channel is closed.
// 5. It will continously collect order data for all channels until any of the above conditions are broken.
// 6. All channel data are collected once for the receiving scope, i.e a channels data will not be received twice into the return slice
//    but all channels will have a single data slot for a partial data collection session.
// 7. Will continue to gather data from provided channels until all are closed or the context has expired.
// 8. If any of the senders is nil then the returned channel will be closed, has this leaves things in an unstable state.
func Complex128CombineInOrder(ctx context.Context, maxItemWait time.Duration, senders ...chan complex128) chan []complex128 {
	res := make(chan []complex128, 0)

	for _, elem := range senders {
		if elem == nil {
			close(res)
			return res
		}
	}

	go func() {
		content := make([]complex128, len(senders))

		var index int

		total := len(senders)
		filled := make(map[int]bool, 0)

		for {
			// if the current index has being filled, shift forward and reattempt loop.
			if filled[index] {
				index++
				continue
			}

			if len(filled) == total {
				res <- content
				index = 0
				filled = make(map[int]bool, 0)
				content = make([]complex128, len(senders))
			}

			timer := time.NewTimer(maxItemWait)

			select {
			case <-ctx.Done():
				close(res)
				timer.Stop()
				return
			case <-timer.C:
				switch index >= total {
				case true:
					index = 0
				case false:
					index++
				}
			case data, ok := <-senders[index]:
				if !ok {
					close(res)
					timer.Stop()
					return
				}

				content[index] = data
				filled[index] = true
				index++
			}

			timer.Stop()
		}

	}()

	return res
}

// Complex128Distributor delivers messages to subscription channels which it manages internal,
// ensuring every subscriber gets the delivered message, it guarantees that every subscribe will get the chance to receive a
// messsage unless it takes more than a giving duration of time, and if passing that duration that the operation
// to deliver will be cancelled, this ensures that we do not leak goroutines nor
// have eternal channel blocks.
type Complex128Distributor struct {
	running             int64
	messages            chan complex128
	close               chan struct{}
	clear               chan struct{}
	subscribers         []chan complex128
	newSub              chan chan complex128
	sendWaitBeforeAbort time.Duration
}

// NewComplex128Disributor returns a new instance of a Complex128Distributor.
func NewComplex128Disributor(buffer int, sendWaitBeforeAbort time.Duration) *Complex128Distributor {
	if sendWaitBeforeAbort <= 0 {
		sendWaitBeforeAbort = defaultSendWithBeforeAbort
	}

	return &Complex128Distributor{
		clear:               make(chan struct{}, 0),
		close:               make(chan struct{}, 0),
		subscribers:         make([]chan complex128, 0),
		newSub:              make(chan chan complex128, 0),
		messages:            make(chan complex128, buffer),
		sendWaitBeforeAbort: sendWaitBeforeAbort,
	}
}

// PublishDeadline sends the message into the distributor to be delivered to all subscribers if it has not
// passed the provided deadline.
func (d *Complex128Distributor) PublishDeadline(message complex128, dur time.Duration) {
	if atomic.LoadInt64(&d.running) == 0 {
		return
	}

	timer := time.NewTimer(dur)
	defer timer.Stop()

	select {
	case <-timer.C:
		return
	case d.messages <- message:
		return
	}
}

// Publish sends the message into the distributor to be delivered to all subscribers.
func (d *Complex128Distributor) Publish(message complex128) {
	if atomic.LoadInt64(&d.running) == 0 {
		return
	}

	d.messages <- message
}

// Subscribe adds the channel into the distributor subscription lists.
func (d *Complex128Distributor) Subscribe(sub chan complex128) {
	if atomic.LoadInt64(&d.running) == 0 {
		return
	}

	d.newSub <- sub
}

// Clear removes all subscribers from the distributor.
func (d *Complex128Distributor) Clear() {
	if atomic.LoadInt64(&d.running) == 0 {
		return
	}

	d.clear <- struct{}{}
}

// Stop halts internal delivery behaviour of the distributor.
func (d *Complex128Distributor) Stop() {
	if atomic.LoadInt64(&d.running) == 0 {
		return
	}

	d.close <- struct{}{}
}

// Start initializes the distributor to deliver messages to subscribers.
func (d *Complex128Distributor) Start() {
	if atomic.LoadInt64(&d.running) != 0 {
		return
	}

	atomic.AddInt64(&d.running, 1)
	go d.manage()
}

// manage implements necessary logic to manage message delivery and
// subscriber adding
func (d *Complex128Distributor) manage() {
	defer atomic.AddInt64(&d.running, -1)

	for {
		select {
		case <-d.clear:
			d.subscribers = nil

		case newSub, ok := <-d.newSub:
			if !ok {
				return
			}

			d.subscribers = append(d.subscribers, newSub)
		case message, ok := <-d.messages:
			if !ok {
				return
			}

			for _, sub := range d.subscribers {
				go func(c chan complex128) {
					tick := time.NewTimer(d.sendWaitBeforeAbort)
					defer tick.Stop()

					select {
					case sub <- message:
						return
					case <-tick.C:
						return
					}
				}(sub)
			}
		case <-d.close:
			return
		}
	}
}

// MonoComplex128Service defines a interface for underline systems which want to communicate like
// in a stream using channels to send/recieve only complex128 values from a single source.
// It allows different services to create adapters to
// transform data coming in and out from the Service.
// Auto-Generated using the moz code-generator https://github.com/influx6/moz.
// @iface
type MonoComplex128Service interface {
	// Read will return a channel which will allow reading from the Service until it it is closed.
	Read() (<-chan complex128, error)

	// ReadErrors will return a channel which will allow reading errors from the Service until it it is closed.
	ReadErrors() (<-chan error, error)

	// Receive will take the channel, which will be writing into the Service for it's internal processing
	// and the Service will continue to read form the channel till the channel is closed.
	// Useful for collating/collecting services.
	Write(<-chan complex128) error

	// Done defines a signal to other pending services to know whether the Service is still servicing
	// request.
	Done() chan struct{}

	// Service defines a function to be called to stop the Service internal operation and to close
	// all read/write operations.
	Stop() error
}

// Complex128Service defines a interface for underline systems which want to communicate like
// in a stream using channels to send/recieve complex128 values. It allows different services to create adapters to
// transform data coming in and out from the Service.
// Auto-Generated using the moz code-generator https://github.com/influx6/moz.
// @iface
type Complex128Service interface {
	// Read will return a channel which will allow reading from the Service until it it is closed.
	Read(string) (<-chan complex128, error)

	// ReadErrors will return a channel which will allow reading errors from the Service until it it is closed.
	ReadErrors() (<-chan error, error)

	// Receive will take the channel, which will be writing into the Service for it's internal processing
	// and the Service will continue to read form the channel till the channel is closed.
	// Useful for collating/collecting services.
	Write(string, <-chan complex128) error

	// Done defines a signal to other pending services to know whether the Service is still servicing
	// request.
	Done() chan struct{}

	// Service defines a function to be called to stop the Service internal operation and to close
	// all read/write operations.
	Stop() error
}
